{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppFs0D0MEWRc"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow tensorflow_recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21gO9j8jGoh-",
    "outputId": "b3fdec17-fefa-400c-e726-b13413cc2534"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JdzoYHzYGw2B",
    "outputId": "07e55ced-754d-4c56-df3d-8e1491ca4bec"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/My Drive/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMPFNUmV_uBD"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from ast import literal_eval\n",
    "from datetime import datetime\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxmZNqOkwKXf"
   },
   "outputs": [],
   "source": [
    "def get_text(text, obj='name'):\n",
    "    text = literal_eval(text)\n",
    "\n",
    "    if len(text) == 1:\n",
    "        for i in text:\n",
    "            return i[obj]\n",
    "    else:\n",
    "        s = []\n",
    "        for i in text:\n",
    "            s.append(i[obj])\n",
    "        return ', '.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgUnv3Ys5ui1"
   },
   "outputs": [],
   "source": [
    "credits = pd.read_csv('credits.csv')\n",
    "keywords = pd.read_csv('keywords.csv')\n",
    "movies = pd.read_csv('movies_metadata.csv')\n",
    "ratings_df = pd.read_csv('ratings_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IGGjSB6_5Xd"
   },
   "outputs": [],
   "source": [
    "movies.drop(['belongs_to_collection', 'homepage', 'imdb_id', 'poster_path', 'status', 'title', 'video'], axis=1, inplace=True)\n",
    "movies.drop([19730, 29503, 35587], inplace=True)\n",
    "movies['id'] = movies['id'].astype('int64')\n",
    "\n",
    "df = movies.merge(keywords, on='id').merge(credits, on='id')\n",
    "df['original_language'] = df['original_language'].fillna('')\n",
    "df['runtime'] = df['runtime'].fillna(0)\n",
    "df['tagline'] = df['tagline'].fillna('')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['genres'] = df['genres'].apply(get_text)\n",
    "df['production_companies'] = df['production_companies'].apply(get_text)\n",
    "df['production_countries'] = df['production_countries'].apply(get_text)\n",
    "df['crew'] = df['crew'].apply(get_text)\n",
    "df['spoken_languages'] = df['spoken_languages'].apply(get_text)\n",
    "df['keywords'] = df['keywords'].apply(get_text)\n",
    "df['characters'] = df['cast'].apply(get_text, obj='character')\n",
    "df['actors'] = df['cast'].apply(get_text)\n",
    "\n",
    "df.drop('cast', axis=1, inplace=True)\n",
    "df = df[~df['original_title'].duplicated()]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "ratings_df['date'] = ratings_df['timestamp'].apply(\n",
    "    lambda x: datetime.fromtimestamp(x))\n",
    "ratings_df.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "ratings_df = ratings_df.merge(\n",
    "    df[['id', 'original_title', 'genres', 'overview']], left_on='movieId', right_on='id', how='left')\n",
    "ratings_df = ratings_df[~ratings_df['id'].isna()]\n",
    "ratings_df.drop('id', axis=1, inplace=True)\n",
    "ratings_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "movies_df = df[['id', 'original_title']]\n",
    "movies_df.rename(columns={'id': 'movieId'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "id": "n-utJ-OsTPcD",
    "outputId": "9eb10e75-cf7e-48c7-ad13-7a8745f3ef28"
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "hnZVhqf9TQyE",
    "outputId": "b9568558-f173-470a-e24c-e88efd8f3194"
   },
   "outputs": [],
   "source": [
    "ratings_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "KXcqJHGMTTYL",
    "outputId": "cfed30d1-858c-4de2-dcf1-23ff26e83348"
   },
   "outputs": [],
   "source": [
    "movies_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1geDFIq2AHG8",
    "outputId": "4b38838c-dabf-4e88-ec9a-77e2d91fdb3c"
   },
   "outputs": [],
   "source": [
    "ratings_df['userId'] = ratings_df['userId'].astype(str)\n",
    "\n",
    "ratings = tf.data.Dataset.from_tensor_slices(dict(ratings_df[['userId', 'original_title', 'rating']]))\n",
    "movies = tf.data.Dataset.from_tensor_slices(dict(movies_df[['original_title']]))\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"original_title\": x[\"original_title\"],\n",
    "    \"userId\": x[\"userId\"],\n",
    "    \"rating\": float(x[\"rating\"])\n",
    "})\n",
    "\n",
    "movies = movies.map(lambda x: x[\"original_title\"])\n",
    "print(f'Total Data: {len(ratings)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "koq3k2emKK90",
    "outputId": "14d7dca4-9118-4898-b8b8-dda180feef54"
   },
   "outputs": [],
   "source": [
    "ratings.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvrjYbcBAJkg"
   },
   "outputs": [],
   "source": [
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JItXPJTbALQt",
    "outputId": "90df99d2-c7a7-433e-aa56-225ce87387ba"
   },
   "outputs": [],
   "source": [
    "movie_titles = movies.batch(512)\n",
    "user_id = ratings.batch(512).map(lambda x: x[\"userId\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_id = np.unique(np.concatenate(list(user_id)))\n",
    "\n",
    "print(f'Unique Movies: {len(unique_movie_titles)}')\n",
    "print(f'Unique users: {len(unique_user_id)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "doimcT80mJKV"
   },
   "outputs": [],
   "source": [
    "class MovieModel(tfrs.models.Model):\n",
    "    def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "        super().__init__()\n",
    "        embedding_dimension = 64\n",
    "        \n",
    "        self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_movie_titles, mask_token=None),\n",
    "            tf.keras.layers.Embedding(\n",
    "                len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "        \n",
    "        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "            tf.keras.layers.StringLookup(\n",
    "                vocabulary=unique_user_id, mask_token=None),\n",
    "            tf.keras.layers.Embedding(\n",
    "                len(unique_user_id) + 1, embedding_dimension)\n",
    "        ])\n",
    "        \n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation='relu'),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ])\n",
    "        \n",
    "        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "        \n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=movies.batch(128).map(self.movie_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        user_embeddings = self.user_model(features['userId'])\n",
    "        movie_embeddings = self.movie_model(features['original_title'])\n",
    "\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        ratings = features.pop('rating')\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=ratings,\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "        return (self.rating_weight * rating_loss\n",
    "                + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YovjbedAYzA"
   },
   "outputs": [],
   "source": [
    "model = MovieModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yR24mnL--7sf",
    "outputId": "c80a3a0e-5ab3-4121-be83-372b86bff70e"
   },
   "outputs": [],
   "source": [
    "model.fit(train.batch(128), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnL0fjqDAg67"
   },
   "outputs": [],
   "source": [
    "metrics = model.evaluate(test.batch(128), return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-iSkkGuX-5WK"
   },
   "outputs": [],
   "source": [
    "print(f\"\\nRetrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zauykHoPAjqM"
   },
   "outputs": [],
   "source": [
    "def predict_movie(user, n):\n",
    "    index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "    index.index_from_dataset(\n",
    "        tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    "    )\n",
    "    _, titles = index(tf.constant([str(user)]))\n",
    "    \n",
    "    print(f'Top {n} recommendations for user {user}:')\n",
    "    for i, title in enumerate(titles[0, :n].numpy()):\n",
    "        print(f'{i + 1}. {title.decode(\"utf-8\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_C6UnqZcqeK"
   },
   "outputs": [],
   "source": [
    "def predict_rating(user, movie):\n",
    "    movie_embeddings, user_embeddings, predicted_rating = model({\n",
    "        \"userId\": np.array([str(user)]),\n",
    "        \"original_title\": np.array([movie])\n",
    "    })\n",
    "    \n",
    "    print(f\"Predicted rating for {movie}: {predicted_rating.numpy()[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_VbQQoLtAmAM",
    "outputId": "da84b2ea-f67f-4faf-fabe-19d63682ee8d"
   },
   "outputs": [],
   "source": [
    "predict_movie(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YsmrpHKNAoXw",
    "outputId": "00c278dd-4bb9-4ecf-e444-cb212cfefa9d"
   },
   "outputs": [],
   "source": [
    "predict_rating(5, 'The Searchers')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
